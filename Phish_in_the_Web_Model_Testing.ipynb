{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Phish in the Web**\n",
        "\n",
        "### **Model Testing**\n",
        "\n",
        "**Data Preprocessing**"
      ],
      "metadata": {
        "id": "6yosfERSxz7x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKgE6YezxiEI",
        "outputId": "99f87bd2-6b4b-4c58-c82e-2134d3fa2a07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-8d3d8e5aa39e>:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  phishing_features_df[feature_columns] = min_scaler.fit_transform(phishing_features_df[feature_columns])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training: Features' shape [no. of examples * feature vector size] =  (8000, 48)\n",
            "Training: Label's shape [no. of examples * 1] = (8000, 1)\n",
            "\n",
            "Test: Features' shape [no. of examples * feature vector size] =  (2000, 48)\n",
            "Test: Label's shape [no. of examples * 1] = (2000, 1)\n",
            "\n",
            "Validation: Features' shape [no. of examples * feature vector size] = (900, 48)\n",
            "Validation: Label's shape [no. of examples * 1] = (900, 1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#import libraries only ONCE\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler #no one hot // all columns numeric\n",
        "from sklearn.model_selection import train_test_split #data splitting\n",
        "\n",
        "\n",
        "#read in data & check for shape\n",
        "phish_df = pd.read_csv(\"Phishing_Legitimate_full.csv\")\n",
        "phish_df.shape\n",
        "\n",
        "#specifying the columns we want to keep\n",
        "selected_columns = ['NumDots', 'SubdomainLevel', 'PathLevel', 'UrlLength', 'NumDash',\n",
        "    'NumDashInHostname', 'AtSymbol','TildeSymbol', 'NumUnderscore','NumPercent',\n",
        "    'NumQueryComponents','NumAmpersand','NumHash','NumNumericChars','NoHttps',\n",
        "    'RandomString','IpAddress','DomainInSubdomains','DomainInPaths','HttpsInHostname','HostnameLength',\n",
        "    'PathLength','QueryLength','DoubleSlashInPath','NumSensitiveWords','EmbeddedBrandName',\n",
        "    'PctExtHyperlinks','PctExtResourceUrls','ExtFavicon','InsecureForms','RelativeFormAction',\n",
        "    'ExtFormAction','AbnormalFormAction','PctNullSelfRedirectHyperlinks','FrequentDomainNameMismatch',\n",
        "    'FakeLinkInStatusBar','RightClickDisabled','PopUpWindow','SubmitInfoToEmail','IframeOrFrame',\n",
        "    'MissingTitle','ImagesOnlyInForm','SubdomainLevelRT','UrlLengthRT','PctExtResourceUrlsRT',\n",
        "    'AbnormalExtFormActionR','ExtMetaScriptLinkRT','PctExtNullSelfRedirectHyperlinksRT', 'CLASS_LABEL']\n",
        "\n",
        "#features\n",
        "feature_columns = ['NumDots', 'SubdomainLevel', 'PathLevel', 'UrlLength', 'NumDash', 'NumDashInHostname', 'AtSymbol','TildeSymbol', 'NumUnderscore','NumPercent','NumQueryComponents','NumAmpersand','NumHash','NumNumericChars','NoHttps','RandomString','IpAddress','DomainInSubdomains','DomainInPaths','HttpsInHostname','HostnameLength','PathLength','QueryLength','DoubleSlashInPath','NumSensitiveWords','EmbeddedBrandName','PctExtHyperlinks','PctExtResourceUrls','ExtFavicon','InsecureForms','RelativeFormAction', 'ExtFormAction','AbnormalFormAction','PctNullSelfRedirectHyperlinks','FrequentDomainNameMismatch','FakeLinkInStatusBar','RightClickDisabled','PopUpWindow','SubmitInfoToEmail','IframeOrFrame','MissingTitle','ImagesOnlyInForm','SubdomainLevelRT','UrlLengthRT','PctExtResourceUrlsRT','AbnormalExtFormActionR','ExtMetaScriptLinkRT','PctExtNullSelfRedirectHyperlinksRT']\n",
        "    #without class label\n",
        "\n",
        "#label\n",
        "label_columns = ['CLASS_LABEL']\n",
        "\n",
        "phishing_features_df = phish_df[feature_columns]\n",
        "phishing_label_df = phish_df[label_columns]\n",
        "\n",
        "phishing_features_df.head()\n",
        "\n",
        "#initiate scaler\n",
        "min_scaler = MinMaxScaler()\n",
        "\n",
        "#scale features // this includes id (maybe drop later)\n",
        "phishing_features_df[feature_columns] = min_scaler.fit_transform(phishing_features_df[feature_columns])\n",
        "\n",
        "phishing_features_df.head()\n",
        "\n",
        "#data splitting\n",
        "\n",
        "#split the data into 70% train, 20% test, and 10% validation\n",
        "x_train, x_temp, y_train, y_temp = train_test_split(phishing_features_df, phishing_label_df, test_size=0.3, random_state=42)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.7, random_state=42)\n",
        "\n",
        "#split data!\n",
        "x_train, x_test, y_train, y_test = train_test_split(phishing_features_df, phishing_label_df, test_size=0.2, random_state=42)\n",
        "\n",
        "#print training data shape and label's shape\n",
        "print (f\"Training: Features' shape [no. of examples * feature vector size] =  {x_train.shape}\")\n",
        "print (f\"Training: Label's shape [no. of examples * 1] = {y_train.shape}\\n\")\n",
        "\n",
        "#print test data shape and label's shape\n",
        "print (f\"Test: Features' shape [no. of examples * feature vector size] =  {x_test.shape}\")\n",
        "print (f\"Test: Label's shape [no. of examples * 1] = {y_test.shape}\\n\")\n",
        "\n",
        "#print validation data shape and label's shape\n",
        "print(f\"Validation: Features' shape [no. of examples * feature vector size] = {x_val.shape}\")\n",
        "print(f\"Validation: Label's shape [no. of examples * 1] = {y_val.shape}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train all Models**\n",
        "\n",
        "- Logistic Regression\n",
        "\n",
        "- Random Forest\n",
        "\n",
        "- SVM\n",
        "\n",
        "- MLP\n",
        "\n",
        "**import necessary files**"
      ],
      "metadata": {
        "id": "Ah8qsWj6x_7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#do i need this\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix"
      ],
      "metadata": {
        "id": "9fUUWWG4yFxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**testing all models**"
      ],
      "metadata": {
        "id": "9FDOBuYHyMGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM\n",
        "svm_model = SVC(kernel=\"linear\")\n",
        "svm_model.fit(x_train, y_train.values.ravel())  #ravel() to convert y_train to 1d array\n",
        "svm_predictions = svm_model.predict(x_test)\n",
        "\n",
        "print(\"SVM Classification Report:\")\n",
        "print(classification_report(y_test, svm_predictions))\n",
        "\n",
        "#Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(x_train, y_train.values.ravel())\n",
        "rf_predictions = rf_model.predict(x_test)\n",
        "\n",
        "print(\"\\nRandom Forest Classification Report:\")\n",
        "print(classification_report(y_test, rf_predictions))\n",
        "\n",
        "#MLP (Multi-Layer Perceptron)\n",
        "mlp_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
        "mlp_model.fit(x_train, y_train.values.ravel())\n",
        "mlp_predictions = mlp_model.predict(x_test)\n",
        "\n",
        "print(\"\\nMLP Classification Report:\")\n",
        "print(classification_report(y_test, mlp_predictions))\n",
        "\n",
        "# Logistic Regression\n",
        "logistic_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "logistic_model.fit(x_train, y_train.values.ravel())\n",
        "logistic_predictions = logistic_model.predict(x_test)\n",
        "\n",
        "print(\"\\nLogistic Regression Classification Report:\")\n",
        "print(classification_report(y_test, logistic_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShkXUOoHyLuz",
        "outputId": "43169510-05e9-45d4-d1ae-b754f1286f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94       988\n",
            "           1       0.93      0.95      0.94      1012\n",
            "\n",
            "    accuracy                           0.94      2000\n",
            "   macro avg       0.94      0.94      0.94      2000\n",
            "weighted avg       0.94      0.94      0.94      2000\n",
            "\n",
            "\n",
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98       988\n",
            "           1       0.98      0.98      0.98      1012\n",
            "\n",
            "    accuracy                           0.98      2000\n",
            "   macro avg       0.98      0.98      0.98      2000\n",
            "weighted avg       0.98      0.98      0.98      2000\n",
            "\n",
            "\n",
            "MLP Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98       988\n",
            "           1       0.98      0.98      0.98      1012\n",
            "\n",
            "    accuracy                           0.98      2000\n",
            "   macro avg       0.98      0.98      0.98      2000\n",
            "weighted avg       0.98      0.98      0.98      2000\n",
            "\n",
            "\n",
            "Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94       988\n",
            "           1       0.93      0.95      0.94      1012\n",
            "\n",
            "    accuracy                           0.94      2000\n",
            "   macro avg       0.94      0.94      0.94      2000\n",
            "weighted avg       0.94      0.94      0.94      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to print evaluation metrics\n",
        "def print_evaluation_metrics(y_true, y_pred):\n",
        "    print(\"ROC AUC Score:\", roc_auc_score(y_true, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "\n",
        "# SVM Evaluation Metrics\n",
        "print(\"\\nSVM Evaluation Metrics:\")\n",
        "print_evaluation_metrics(y_test, svm_predictions)\n",
        "\n",
        "# Random Forest Evaluation Metrics\n",
        "print(\"\\nRandom Forest Evaluation Metrics:\")\n",
        "print_evaluation_metrics(y_test, rf_predictions)\n",
        "\n",
        "# MLP Evaluation Metrics\n",
        "print(\"\\nMLP Evaluation Metrics:\")\n",
        "print_evaluation_metrics(y_test, mlp_predictions)\n",
        "\n",
        "# Logistic Regression Evaluation Metrics\n",
        "print(\"\\nLogistic Regression Evaluation Metrics:\")\n",
        "print_evaluation_metrics(y_test, logistic_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XT5eWHcqygnO",
        "outputId": "ec80a313-0faa-493c-ee37-593fc383705b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVM Evaluation Metrics:\n",
            "ROC AUC Score: 0.940389416075915\n",
            "Confusion Matrix:\n",
            " [[920  68]\n",
            " [ 51 961]]\n",
            "\n",
            "Random Forest Evaluation Metrics:\n",
            "ROC AUC Score: 0.9819974076266982\n",
            "Confusion Matrix:\n",
            " [[970  18]\n",
            " [ 18 994]]\n",
            "\n",
            "MLP Evaluation Metrics:\n",
            "ROC AUC Score: 0.9785389096029828\n",
            "Confusion Matrix:\n",
            " [[970  18]\n",
            " [ 25 987]]\n",
            "\n",
            "Logistic Regression Evaluation Metrics:\n",
            "ROC AUC Score: 0.938389128034437\n",
            "Confusion Matrix:\n",
            " [[918  70]\n",
            " [ 53 959]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RF\n",
        "rf_val_predictions = rf_model.predict(x_val)\n",
        "\n",
        "print(\"Random Forest Validation Classification Report:\")\n",
        "print(classification_report(y_val, rf_val_predictions))\n",
        "\n",
        "print(\"\\nRandom Forest Validation Evaluation Metrics:\")\n",
        "print_evaluation_metrics(y_val, rf_val_predictions)\n",
        "\n",
        "print() #space\n",
        "\n",
        "#MLP\n",
        "mlp_val_predictions = mlp_model.predict(x_val)\n",
        "\n",
        "print(\"MLP Validation Classification Report:\")\n",
        "print(classification_report(y_val, mlp_val_predictions))\n",
        "\n",
        "print(\"\\nMLP Validation Evaluation Metrics:\")\n",
        "print_evaluation_metrics(y_val, mlp_val_predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AAO_p4lPjUV",
        "outputId": "643e0562-ffbc-4b17-cf2d-727480225f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       426\n",
            "           1       0.99      0.99      0.99       474\n",
            "\n",
            "    accuracy                           0.99       900\n",
            "   macro avg       0.99      0.99      0.99       900\n",
            "weighted avg       0.99      0.99      0.99       900\n",
            "\n",
            "\n",
            "Random Forest Validation Evaluation Metrics:\n",
            "ROC AUC Score: 0.9922594639567363\n",
            "Confusion Matrix:\n",
            " [[423   3]\n",
            " [  4 470]]\n",
            "\n",
            "MLP Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       426\n",
            "           1       0.99      0.98      0.99       474\n",
            "\n",
            "    accuracy                           0.99       900\n",
            "   macro avg       0.99      0.99      0.99       900\n",
            "weighted avg       0.99      0.99      0.99       900\n",
            "\n",
            "\n",
            "MLP Validation Evaluation Metrics:\n",
            "ROC AUC Score: 0.9868663457538479\n",
            "Confusion Matrix:\n",
            " [[422   4]\n",
            " [  8 466]]\n"
          ]
        }
      ]
    }
  ]
}